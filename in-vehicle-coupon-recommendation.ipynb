{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f1a43d",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170957bd",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0d349a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/in-vehicle-coupon-recommendation.csv\")\n",
    "\n",
    "# print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048538c3",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50ef562",
   "metadata": {},
   "source": [
    "As a very first step we are going to drop 2 of the features from our dataset, one of them being the feature car, because our dataset includes values of this feature for only 109 records, and the second one will be direction_opp, because it's the complete opposite of direction_same and together they would be redundant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "68727995",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['car','direction_opp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632002e4",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbfc8c",
   "metadata": {},
   "source": [
    "One of our features has mixed values. That is the feature age and the possible values are the following: \"21, 46, 26, 31, 41, 50plus, 36, below21\". For that reason we will try to engineer new columns based on this one, we will try 2 options: converting it to numeric values and categorical and we'll see which one does better for our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "06ae8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_age_categorical(value):\n",
    "    try:\n",
    "        value = int(value)\n",
    "        if value < 21:\n",
    "            return \"<21\"\n",
    "        elif value <= 30:\n",
    "            return \"21-30\"\n",
    "        elif value <= 40:\n",
    "            return \"31-40\"\n",
    "        elif value <= 50:\n",
    "            return \"41-50\"\n",
    "        else:\n",
    "            return \"51+\"\n",
    "    except:\n",
    "        if str(value).lower() == \"below21\":\n",
    "            return \"<21\"\n",
    "        elif str(value).lower() == \"50plus\":\n",
    "            return \"51+\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "        \n",
    "\n",
    "def convert_age_numeric(value):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except:\n",
    "        mapping = {\n",
    "            \"below21\": 20,\n",
    "            \"50plus\": 55\n",
    "        }\n",
    "        return mapping.get(value.strip(), None)\n",
    "\n",
    "\n",
    "data['age_numeric'] = data['age'].apply(convert_age_numeric)\n",
    "data['age_group'] = data['age'].apply(convert_age_categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ec3da",
   "metadata": {},
   "source": [
    "We will try a similar engineering with income featue, which has the following values: \"$37500 - $49999, $62500 - $74999, $12500 - $24999, $75000 - $87499, $50000 - $62499, $25000 - $37499, $100000 or More, $87500 - $99999, Less than $12500\". \n",
    "As we can see there is obviously an ordered numeric meaning behind it, so we will try 2 way again: categorical and numeric.\n",
    "\n",
    "We are going to drop former age and income columns after engineering new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "afd3da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_income_numeric(value):\n",
    "    value = value.strip()\n",
    "\n",
    "    if value == \"Less than $12500\":\n",
    "        return 6250\n",
    "    elif value == \"$12500 - $24999\":\n",
    "        return (12500 + 24999) / 2\n",
    "    elif value == \"$25000 - $37499\":\n",
    "        return (25000 + 37499) / 2\n",
    "    elif value == \"$37500 - $49999\":\n",
    "        return (37500 + 49999) / 2\n",
    "    elif value == \"$50000 - $62499\":\n",
    "        return (50000 + 62499) / 2\n",
    "    elif value == \"$62500 - $74999\":\n",
    "        return (62500 + 74999) / 2\n",
    "    elif value == \"$75000 - $87499\":\n",
    "        return (75000 + 87499) / 2\n",
    "    elif value == \"$87500 - $99999\":\n",
    "        return (87500 + 99999) / 2\n",
    "    elif value == \"$100000 or More\":\n",
    "        return 110000\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def convert_income_categorical(value):\n",
    "    mapping = {\n",
    "        \"Less than $12500\": \"Under 12.5k\",\n",
    "        \"$12500 - $24999\": \"12.5k-25k\",\n",
    "        \"$25000 - $37499\": \"25k-37k\",\n",
    "        \"$37500 - $49999\": \"37k-49k\",\n",
    "        \"$50000 - $62499\": \"50k-62k\",\n",
    "        \"$62500 - $74999\": \"62k-74k\",\n",
    "        \"$75000 - $87499\": \"75k-87k\",\n",
    "        \"$87500 - $99999\": \"87k-99k\",\n",
    "        \"$100000 or More\": \"100k+\"\n",
    "    }\n",
    "    return mapping.get(value.strip(), None)\n",
    "\n",
    "data['income_numeric'] = data['income'].apply(convert_income_numeric)\n",
    "data['income_group'] = data['income'].apply(convert_income_categorical)\n",
    "data = data.drop(['age', 'income'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f62f4",
   "metadata": {},
   "source": [
    "### Cyclical encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62dc546",
   "metadata": {},
   "source": [
    "For the time feature, we will use cyclical encoding because it has a circular structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c0cb8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "times = [\"2PM\", \"10AM\", \"6PM\", \"7AM\", \"10PM\"]\n",
    "\n",
    "def convert_time_to_hour(time):\n",
    "    return pd.to_datetime(time, format='%I%p').hour\n",
    "\n",
    "data['hour'] = data['time'].apply(convert_time_to_hour)\n",
    "\n",
    "data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "data = data.drop('time', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8d9a8",
   "metadata": {},
   "source": [
    "### Bias, Skew, Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skew\n",
    "print(\"Skew\")\n",
    "skew_features = ['temperature', 'age_numeric', 'income_numeric']\n",
    "print(data[skew_features].skew())\n",
    "\n",
    "\n",
    "# # Correlation\n",
    "print(\"Correlation\")\n",
    "corr_features = ['temperature', 'income_numeric', 'age_numeric', 'hour_sin', 'hour_cos']\n",
    "corr_matrix = data[corr_features].corr()\n",
    "\n",
    "print(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c142585",
   "metadata": {},
   "source": [
    "Modifications on features based on skew and correlation. \n",
    "\n",
    "We have moderate negative (left skew) for temperature and moderate positive (right skew) for age_numeric, so what we'll do is use Box-Cox transformer, which automaticall handles both left and right skewness of the data, and works only for positive values, which is the case for both of our features. \n",
    "\n",
    "And based on the correlation matrix our features look good, no strong correlation between variables so we can keep all of them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3e4bffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "skewed_features_to_transform = ['temperature', 'age_numeric']\n",
    "\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "data_transformed = data.copy()\n",
    "data_transformed[skewed_features_to_transform] = pt.fit_transform(data[skewed_features_to_transform])\n",
    "\n",
    "# set(data.columns) == set(data_transformed.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f221828",
   "metadata": {},
   "source": [
    "Now let's look at the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af1f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias\n",
    "bias_features = ['gender', 'maritalStatus', 'occupation', 'passanger', 'destination', 'coupon', 'weather', 'education', 'income_group', 'age_group', 'has_children', 'toCoupon_GEQ5min', 'toCoupon_GEQ15min', 'toCoupon_GEQ25min', 'direction_same']\n",
    "print(\"Bias\")\n",
    "for col in bias_features:\n",
    "    # print(data[col].value_counts(normalize=True))\n",
    "\n",
    "    print(f\"\\n--- Value Distribution for '{col}' ---\")\n",
    "    print(data[col].value_counts(normalize=True).rename(\"proportion\").to_frame())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b11784a",
   "metadata": {},
   "source": [
    "One of the features that is imbalanced is marital status. So what we'll do is join some of the groups into one for the less represented groups to have more statistical effect and to reduce the noise in the data, this will help to avoid overfitting in our models.\n",
    "\n",
    "We can say the same about education and occupation. So we will do the same re-grouping for them. In case of occupation, though we also have high cardinality, so it will help with this issue as well. \n",
    "\n",
    "We can also see that 2 of our features, weather and direction_same, we also have very high bias. But it was decided to keep these variables as they are because in our opinion they may hold important information and we don't want to lose it at early stages. \n",
    "\n",
    "Lastly, we will drop toCoupon_GEQ25min, because it has 88% 0s in it, and toCoupon_GEQ5min, because all the values here are the same, these features will be redundant in our analysis, and after all we also have toCoupon_GEQ15min, which is balanced and can give us an idea whether the driving distance effects the decision making or no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2cb8ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        proportion\n",
      "education_group                                   \n",
      "Some College                              0.433933\n",
      "Bachelors degree                          0.341769\n",
      "Graduate degree (Masters or Doctorate)    0.146011\n",
      "High School or Less                       0.078288\n"
     ]
    }
   ],
   "source": [
    "data_transformed = data_transformed.drop(['toCoupon_GEQ25min', 'toCoupon_GEQ5min'], axis=1)\n",
    "\n",
    "\n",
    "# marital status\n",
    "def group_marital_status(x):\n",
    "    if x in [\"Divorced\", \"Widowed\"]:\n",
    "        return \"Previously Married\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "data_transformed['marital_status_group'] = data_transformed['maritalStatus'].apply(group_marital_status)\n",
    "\n",
    "\n",
    "\n",
    "# education\n",
    "def group_education(x):\n",
    "    if x in [\"Some High School\", \"High School Graduate\"]:\n",
    "        return \"High School or Less\"\n",
    "    elif x in [\"Associates degree\", \"Some college - no degree\"]:\n",
    "        return \"Some College\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "data_transformed['education_group'] = data_transformed['education'].apply(group_education)\n",
    "\n",
    "print(data_transformed['education_group'].value_counts(normalize=True).rename(\"proportion\").to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01179c7",
   "metadata": {},
   "source": [
    "### Encoding ( One-hot and Ordinal )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a62a158",
   "metadata": {},
   "source": [
    "For categorical data like destination, passanger, weather, coupon, gender, marital status, occupation we will use one-hot encoding, which is good for nominal data, when there is no order/ranking between the categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d022385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "nominal_cat_features = ['destination', 'passanger', 'weather', 'coupon', 'gender', 'maritalStatus', 'occupation']\n",
    "\n",
    "seed = 7\n",
    "X = data.drop('Y', axis=1)\n",
    "y = data['Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "\n",
    "one_hot_encoder = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86d31e",
   "metadata": {},
   "source": [
    "For the rest of the categorical data we will use a different method of encoding because these are considered ordinal data, where categories have order/ranking. Some of these features also have missing values, so we will replace them with the most frequent value of the category.\n",
    "\n",
    "We also give the order of the categories for the processor to know the correct order and give correct importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c1c557dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_cat_features = ['expiration', 'education', 'Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50']\n",
    "\n",
    "ordinal_categories = [\n",
    "    ['2h', '1d'],   # expiration\n",
    "    ['Some High School','High School Graduate', 'Some college - no degree', 'Associates degree', 'Bachelors degree', 'Graduate degree (Masters or Doctorate)'], # education\n",
    "    ['never', 'less1', '1~3', '4~8', 'gt8'],    # Bar\n",
    "    ['never', 'less1', '1~3', '4~8', 'gt8'],    # CoffeeHouse\n",
    "    ['never', 'less1', '1~3', '4~8', 'gt8'],    # CarryAway\n",
    "    ['never', 'less1', '1~3', '4~8', 'gt8'],    # RestaurantLessThan20\n",
    "    ['never', 'less1', '1~3', '4~8', 'gt8']     # Restaurant20To50\n",
    "]\n",
    "\n",
    "ordinal_encoder = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(categories=ordinal_categories))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('nom', one_hot_encoder, nominal_cat_features),\n",
    "    ('ord', ordinal_encoder, ordinal_cat_features)\n",
    "])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
